---
title: "Clustering and Association Rule Mining"
author: "Gayathri Sripathy (u1166213)"
date: "February 28, 2018"
output: 
  html_document:
    number_sections: yes
    theme: readable
    highlight: tango
    toc: yes
    fig_width: 15
    fig_height: 10
---

# To explore trip data by finding similar customer shopping trips using clustering, Walmart_visits_s2018.csv was created via such a feature engineering process to contain the following features:

TripType - a categorical id representing the type of shopping trip the customer made. Trip type, 999, is an "other" category. Walmart_visits_s2018.csv only contains a few of the original 38 trip types.
DOW - Day of Week of the trip
UniqueItems - the number of unique UPC numbers of the products purchased in a visit
TotalQty - the total number of the items that were purchased in a visit
TotalRtrnQty -  the total number of the items returned in a visit
NetQty = total_purchase_quantity - total_return_quantity
UniqueDepts - the number of unique departments representing the purchased items in a visit.
OneItemDepts - the number of unique departments representing single-departmental-product purchases in a visit
RtrnDepts - the number of unique departments representing the returned items in a visit.

# Load packages, prepare and inspect the data
## Package loading, data import and transformation
```{r - Package loading, data import and transformation, warning=FALSE, message=FALSE}
# Load the following packages. Install them first if necessary.
Sys.setenv(JAVA_HOME='C:\\Program Files\\Java\\jre1.8.0_161') # for 64-bit version
library(rJava)
library(caret)
library(kernlab)
library(rminer)
library(matrixStats)
library(knitr)
library(RWeka)
library(C50)
library(psych)
library(knitr)
library(arules)

#Setting up the working directory
#setwd("C:/Users/gayat/Desktop/Data Mining/Assignment 5")

#Importing walmart_baskets_s2018.csv and walmart_visits_s2018.csv datasets and trnsforming character to factor variables
w_visits <- read.csv(file = "walmart_visits_s2018.csv", stringsAsFactors = TRUE)

#Viewing the summary and structure of both the datasets
summary(w_visits)
str(w_visits)
```

## Correlation analysis of walmart_visits_s2018.csv
```{r - correlation analysis of walmart_visits_s2018.csv, warning=FALSE, message=FALSE}
# correlations - exploring relationships among features: correlation matrix
cor(w_visits[c("UniqueItems", "TotalQty", "RtrnQty", "NetQty", "UniqDepts", "OneItemDepts", "RtrnDepts")])
# visualizing correlations
pairs.panels(w_visits)
```

## C5.0 decision tree using the entire data set
```{r - C5.0 decision tree using the entire data set, warning=FALSE, message=FALSE}
#Changing the outcome variable to factor since C5.0 requires a factor variable as outcome
w_visits$TripType <- factor(w_visits$TripType)
#Default C5.0 model
c50_model1 <- C5.0(TripType ~., data = w_visits, control = C5.0Control(CF = 0.24))
#summary of the model to view tree rules and confusion matrix
summary(c50_model1)
#Plotting the tree
plot(c50_model1)
```

# SimpleKMeans clustering  to understand visits
## Input data transformation
```{r - Input data transformation, warning=FALSE, message=FALSE}
# Saving the number of unique TripType in the imported data as TripType.levels. 
TripType.levels <- (nlevels(w_visits$TripType))
TripType <- w_visits$TripType
w_visits <- cbind(w_visits, TripType.levels)
# Remove TripType from input data. 
w_visits <- w_visits[,-1]
```

## Generating clusters with the default (i.e. random) initial cluster assignment and the default distance function (Euclidean)
```{r - Generate clusters with the default (i.e. random) initial cluster assignment and the default distance function (Euclidean), warning=FALSE, message=FALSE}
# Generating clusters with the default (i.e. random) initial cluster assignment and the default distance function (Euclidean). The number of clusters equals to TripType.levels.
w_visits_clustering1 <- SimpleKMeans(w_visits, Weka_control(N=7, init = 0, V=TRUE))
# the standard deviations and the centroids of the clusters
w_visits_clustering1
table(predict(w_visits_clustering1), TripType)
```

## Kmeans++ method cluster assignment
```{r - Kmeans++ method cluster assignment, warning=FALSE, message=FALSE}
# Keeping the number of clusters at TripType.levels and the Euclidean distance function. 
# Changing the initial cluster assignment method to the Kmeans++ method. 
w_visits_clustering2 <- SimpleKMeans(w_visits, Weka_control(N=7, init = 1, V=TRUE))
# the standard deviations and the centroids of the clusters
w_visits_clustering2
table(predict(w_visits_clustering2), TripType)
```

## Using "weka.core.ManhattanDistance" as distance function
```{r - Using "weka.core.ManhattanDistance" as distance function, warning=FALSE, message=FALSE}
# SimpleKmeans with Kmeans++ initial cluster assignment and "weka.core.Manhattandistance"
w_visits_clustering3 <- SimpleKMeans(w_visits, Weka_control(N=7, init=1, A="weka.core.ManhattanDistance", V=TRUE))
# the standard deviations and the centroids of the clusters
w_visits_clustering3
table(predict(w_visits_clustering3), TripType)
```

## Using different distance function and cluster number
```{r - ## Using distance distance function and cluster number, warning=FALSE, message=FALSE}
# Using distance distance function and cluster number
w_visits_clustering4 <- SimpleKMeans(w_visits, Weka_control(N=5, init=1, A="weka.core.ManhattanDistance", V=TRUE))
# the standard deviations and the centroids of the clusters
w_visits_clustering4
table(predict(w_visits_clustering4), TripType)
```

# Market Basket Analysis with the Walmart dept baskets
## Importing Walmart_baskets data
```{r - Importing Walmart_baskets data, warning=FALSE, message=FALSE}
# Import Walmart_baskets_s2018.csv file using the following read.transactions() with the "single" format (for long format) and save it in a sparse matrix called, e.g., Dept_baskets.
Dept_baskets <- read.transactions("Walmart_baskets_s2018.csv", format="single", sep = ",", cols=c("VisitNumber","DepartmentDescription"))
```

## Inspecting the first 15 transactions
```{r - Inspecting the first 15 transactions, warning=FALSE, message=FALSE}
# Inspecting the first 15 transactions using inspect function
summary(Dept_baskets)
inspect(Dept_baskets[1:15])
```

## Transaction frequency in percentage
```{r - Transaction frequency in percentage, warning=FALSE, message=FALSE}
# Using the itemFrequencyPlot command to plot the most frequent 15 items in the descending order of transaction frequency in percentage
itemFrequency(Dept_baskets[1:15])
itemFrequencyPlot(Dept_baskets, topN = 15)
```

## Associate rule mining
### Using apriori command to generate about 50 to 100 association rules from the input data
```{r - Using apriori command to generate about 50 to 100 association rules from the input data, warning=FALSE, message=FALSE}
# Using the apriori command to generate about 50 to 100 association rules from the input data.
# if the thresholds are too low, there will be too many rules, or if they are too high, there will not be enough rules. 
basket_rules <- apriori(Dept_baskets, parameter = list(support =
                          0.0511, confidence = 0.25, minlen = 2))
summary(basket_rules)
# Showing the rules in the descending order of their lift values
inspect(sort(basket_rules, by = "lift"))
```

### Using apriori command to generate about 100 to 200 association rules from the input data
```{r - Using apriori command to generate about 100 to 200 association rules from the input data, warning=FALSE, message=FALSE}
# Using the apriori command to generate about 100 to 200 association rules from the input data.
# if the thresholds are too low, there will be too many rules, or if they are too high, there will not be enough rules. 
basket_rules1 <- apriori(Dept_baskets, parameter = list(support =
                          0.0399, confidence = 0.25, minlen = 2))
summary(basket_rules1)
# Showing the rules in the descending order of their lift values
inspect(sort(basket_rules1, by = "lift"))
```
